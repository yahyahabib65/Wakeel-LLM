{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52228d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Ã— Getting requirements to build wheel did not run successfully.\n",
      "  â”‚ exit code: 1\n",
      "  â•°â”€> [48 lines of output]\n",
      "      Traceback (most recent call last):\n",
      "        File \u001b[35m\"C:\\Users\\hisham.fawad\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\"\u001b[0m, line \u001b[35m389\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "          \u001b[31mmain\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "          \u001b[31m~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "        File \u001b[35m\"C:\\Users\\hisham.fawad\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\"\u001b[0m, line \u001b[35m373\u001b[0m, in \u001b[35mmain\u001b[0m\n",
      "          json_out[\"return_val\"] = \u001b[31mhook\u001b[0m\u001b[1;31m(**hook_input[\"kwargs\"])\u001b[0m\n",
      "                                   \u001b[31m~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "        File \u001b[35m\"C:\\Users\\hisham.fawad\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\"\u001b[0m, line \u001b[35m143\u001b[0m, in \u001b[35mget_requires_for_build_wheel\u001b[0m\n",
      "          return hook(config_settings)\n",
      "        File \u001b[35m\"C:\\Users\\hisham.fawad\\AppData\\Local\\Temp\\pip-build-env-35oyoscf\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\"\u001b[0m, line \u001b[35m334\u001b[0m, in \u001b[35mget_requires_for_build_wheel\u001b[0m\n",
      "          return \u001b[31mself._get_build_requires\u001b[0m\u001b[1;31m(config_settings, requirements=[])\u001b[0m\n",
      "                 \u001b[31m~~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "        File \u001b[35m\"C:\\Users\\hisham.fawad\\AppData\\Local\\Temp\\pip-build-env-35oyoscf\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\"\u001b[0m, line \u001b[35m304\u001b[0m, in \u001b[35m_get_build_requires\u001b[0m\n",
      "          \u001b[31mself.run_setup\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "          \u001b[31m~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "        File \u001b[35m\"C:\\Users\\hisham.fawad\\AppData\\Local\\Temp\\pip-build-env-35oyoscf\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\"\u001b[0m, line \u001b[35m522\u001b[0m, in \u001b[35mrun_setup\u001b[0m\n",
      "          \u001b[31msuper().run_setup\u001b[0m\u001b[1;31m(setup_script=setup_script)\u001b[0m\n",
      "          \u001b[31m~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "        File \u001b[35m\"C:\\Users\\hisham.fawad\\AppData\\Local\\Temp\\pip-build-env-35oyoscf\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\"\u001b[0m, line \u001b[35m320\u001b[0m, in \u001b[35mrun_setup\u001b[0m\n",
      "          \u001b[31mexec\u001b[0m\u001b[1;31m(code, locals())\u001b[0m\n",
      "          \u001b[31m~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^\u001b[0m\n",
      "        File \u001b[35m\"<string>\"\u001b[0m, line \u001b[35m128\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "        File \u001b[35m\"C:\\Users\\hisham.fawad\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\subprocess.py\"\u001b[0m, line \u001b[35m416\u001b[0m, in \u001b[35mcheck_call\u001b[0m\n",
      "          retcode = call(*popenargs, **kwargs)\n",
      "        File \u001b[35m\"C:\\Users\\hisham.fawad\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\subprocess.py\"\u001b[0m, line \u001b[35m397\u001b[0m, in \u001b[35mcall\u001b[0m\n",
      "          with \u001b[31mPopen\u001b[0m\u001b[1;31m(*popenargs, **kwargs)\u001b[0m as p:\n",
      "               \u001b[31m~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "        File \u001b[35m\"C:\\Users\\hisham.fawad\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\subprocess.py\"\u001b[0m, line \u001b[35m1038\u001b[0m, in \u001b[35m__init__\u001b[0m\n",
      "          \u001b[31mself._execute_child\u001b[0m\u001b[1;31m(args, executable, preexec_fn, close_fds,\u001b[0m\n",
      "          \u001b[31m~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "                              \u001b[1;31mpass_fds, cwd, env,\u001b[0m\n",
      "                              \u001b[1;31m^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "          ...<5 lines>...\n",
      "                              \u001b[1;31mgid, gids, uid, umask,\u001b[0m\n",
      "                              \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "                              \u001b[1;31mstart_new_session, process_group)\u001b[0m\n",
      "                              \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "        File \u001b[35m\"C:\\Users\\hisham.fawad\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\subprocess.py\"\u001b[0m, line \u001b[35m1550\u001b[0m, in \u001b[35m_execute_child\u001b[0m\n",
      "          hp, ht, pid, tid = \u001b[31m_winapi.CreateProcess\u001b[0m\u001b[1;31m(executable, args,\u001b[0m\n",
      "                             \u001b[31m~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "                                   \u001b[1;31m# no special security\u001b[0m\n",
      "                                   \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "          ...<4 lines>...\n",
      "                                   \u001b[1;31mcwd,\u001b[0m\n",
      "                                   \u001b[1;31m^^^^\u001b[0m\n",
      "                                   \u001b[1;31mstartupinfo)\u001b[0m\n",
      "                                   \u001b[1;31m^^^^^^^^^^^^\u001b[0m\n",
      "      \u001b[1;35mFileNotFoundError\u001b[0m: \u001b[35m[WinError 2] The system cannot find the file specified\u001b[0m\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "Ã— Getting requirements to build wheel did not run successfully.\n",
      "â”‚ exit code: 1\n",
      "â•°â”€> See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      4\u001b[39m get_ipython().system(\u001b[33m'\u001b[39m\u001b[33mpip install -q transformers datasets peft accelerate bitsandbytes sentencepiece\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# ====================\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# ðŸ”¹ STEP 2: Load Base Model (Phi-2 or Mistral)\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# ====================\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoModelForCausalLM, AutoTokenizer\n\u001b[32m     11\u001b[39m model_name = \u001b[33m\"\u001b[39m\u001b[33mmicrosoft/phi-2\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# Use \"mistralai/Mistral-7B-v0.1\" if you have a GPU\u001b[39;00m\n\u001b[32m     12\u001b[39m tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'transformers'"
     ]
    }
   ],
   "source": [
    "# ====================\n",
    "# ðŸ”¹ STEP 1: Install Required Packages\n",
    "# ====================\n",
    "!pip install -q transformers datasets peft accelerate bitsandbytes sentencepiece\n",
    "\n",
    "# ====================\n",
    "# ðŸ”¹ STEP 2: Load Base Model (Phi-2 or Mistral)\n",
    "# ====================\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name = \"microsoft/phi-2\"  # Use \"mistralai/Mistral-7B-v0.1\" if you have a GPU\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    load_in_4bit=True,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# ====================\n",
    "# ðŸ”¹ STEP 3: Prepare Dataset (Muslim Family Law - Pakistan)\n",
    "# ====================\n",
    "from datasets import Dataset\n",
    "\n",
    "data = [\n",
    "    {\n",
    "        \"instruction\": \"What are the rights of a wife under Muslim Family Law in Pakistan?\",\n",
    "        \"output\": \"Under the Muslim Family Laws Ordinance 1961, a wife has rights including maintenance, dower, and divorce under certain conditions...\"\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"Draft a simple divorce notice under Pakistani law.\",\n",
    "        \"output\": \"Subject: Notice of Divorce\\n\\nTo: [Wife's Name],\\n\\nI, [Husband's Name], hereby pronounce divorce (Talaq)...\"\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"Explain the concept of 'Khula' in Pakistan.\",\n",
    "        \"output\": \"Khula is a form of divorce initiated by the wife, typically through the Family Court, when she cannot live with her husband...\"\n",
    "    }\n",
    "]\n",
    "\n",
    "dataset = Dataset.from_list(data)\n",
    "\n",
    "# ====================\n",
    "# ðŸ”¹ STEP 4: Format Dataset for Instruction Tuning\n",
    "# ====================\n",
    "def format_sample(sample):\n",
    "    return {\n",
    "        \"text\": f\"### Instruction:\\n{sample['instruction']}\\n\\n### Response:\\n{sample['output']}\"\n",
    "    }\n",
    "\n",
    "dataset = dataset.map(format_sample)\n",
    "\n",
    "# ====================\n",
    "# ðŸ”¹ STEP 5: Apply LoRA for Parameter-Efficient Fine-Tuning\n",
    "# ====================\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],  # May vary by model\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "# ====================\n",
    "# ðŸ”¹ STEP 6: Train the Model\n",
    "# ====================\n",
    "from transformers import TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=1,\n",
    "    num_train_epochs=3,\n",
    "    logging_steps=10,\n",
    "    output_dir=\"./lawyer_bot_model\",\n",
    "    save_strategy=\"epoch\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# ====================\n",
    "# ðŸ”¹ STEP 7: Save the Fine-tuned Model\n",
    "# ====================\n",
    "model.save_pretrained(\"./lawyer_bot_model\")\n",
    "tokenizer.save_pretrained(\"./lawyer_bot_model\")\n",
    "\n",
    "# ====================\n",
    "# ðŸ”¹ STEP 8: Use the Lawyer Bot\n",
    "# ====================\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=\"./lawyer_bot_model\", tokenizer=\"./lawyer_bot_model\")\n",
    "\n",
    "response = pipe(\"### Instruction:\\nWhat is the procedure of Khula in Pakistan?\\n\\n### Response:\", max_new_tokens=200)[0]['generated_text']\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20032b84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
