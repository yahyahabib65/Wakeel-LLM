{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52228d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================\n",
    "# ðŸ”¹ STEP 1: Install Required Packages\n",
    "# ====================\n",
    "!pip install -q transformers datasets peft accelerate bitsandbytes sentencepiece\n",
    "\n",
    "# ====================\n",
    "# ðŸ”¹ STEP 2: Load Base Model (Phi-2 or Mistral)\n",
    "# ====================\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name = \"microsoft/phi-2\"  # Use \"mistralai/Mistral-7B-v0.1\" if you have a GPU\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    load_in_4bit=True,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# ====================\n",
    "# ðŸ”¹ STEP 3: Prepare Dataset (Muslim Family Law - Pakistan)\n",
    "# ====================\n",
    "from datasets import Dataset\n",
    "\n",
    "data = [\n",
    "    {\n",
    "        \"instruction\": \"What are the rights of a wife under Muslim Family Law in Pakistan?\",\n",
    "        \"output\": \"Under the Muslim Family Laws Ordinance 1961, a wife has rights including maintenance, dower, and divorce under certain conditions...\"\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"Draft a simple divorce notice under Pakistani law.\",\n",
    "        \"output\": \"Subject: Notice of Divorce\\n\\nTo: [Wife's Name],\\n\\nI, [Husband's Name], hereby pronounce divorce (Talaq)...\"\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"Explain the concept of 'Khula' in Pakistan.\",\n",
    "        \"output\": \"Khula is a form of divorce initiated by the wife, typically through the Family Court, when she cannot live with her husband...\"\n",
    "    }\n",
    "]\n",
    "\n",
    "dataset = Dataset.from_list(data)\n",
    "\n",
    "# ====================\n",
    "# ðŸ”¹ STEP 4: Format Dataset for Instruction Tuning\n",
    "# ====================\n",
    "def format_sample(sample):\n",
    "    return {\n",
    "        \"text\": f\"### Instruction:\\n{sample['instruction']}\\n\\n### Response:\\n{sample['output']}\"\n",
    "    }\n",
    "\n",
    "dataset = dataset.map(format_sample)\n",
    "\n",
    "# ====================\n",
    "# ðŸ”¹ STEP 5: Apply LoRA for Parameter-Efficient Fine-Tuning\n",
    "# ====================\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],  # May vary by model\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "# ====================\n",
    "# ðŸ”¹ STEP 6: Train the Model\n",
    "# ====================\n",
    "from transformers import TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=1,\n",
    "    num_train_epochs=3,\n",
    "    logging_steps=10,\n",
    "    output_dir=\"./lawyer_bot_model\",\n",
    "    save_strategy=\"epoch\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# ====================\n",
    "# ðŸ”¹ STEP 7: Save the Fine-tuned Model\n",
    "# ====================\n",
    "model.save_pretrained(\"./lawyer_bot_model\")\n",
    "tokenizer.save_pretrained(\"./lawyer_bot_model\")\n",
    "\n",
    "# ====================\n",
    "# ðŸ”¹ STEP 8: Use the Lawyer Bot\n",
    "# ====================\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=\"./lawyer_bot_model\", tokenizer=\"./lawyer_bot_model\")\n",
    "\n",
    "response = pipe(\"### Instruction:\\nWhat is the procedure of Khula in Pakistan?\\n\\n### Response:\", max_new_tokens=200)[0]['generated_text']\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
